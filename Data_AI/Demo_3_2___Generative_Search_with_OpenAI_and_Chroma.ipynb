{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. <font color = red> Install and Import the Required Libraries"
      ],
      "metadata": {
        "id": "ghrNO9TjM_mS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PsPVtxoSY_V"
      },
      "outputs": [],
      "source": [
        "# Install all the required libraries\n",
        "\n",
        "!pip install pdfplumber\n",
        "!pip install tiktoken\n",
        "!pip install openai\n",
        "!pip install chromaDB\n",
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all the required Libraries\n",
        "\n",
        "import pdfplumber\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from operator import itemgetter\n",
        "import json\n",
        "import tiktoken\n",
        "import openai\n",
        "import chromadb"
      ],
      "metadata": {
        "id": "R7uDlZS0M99u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "xl87i2pdQUIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. <font color = red> Read, Process, and Chunk the PDF Files\n",
        "\n",
        "We will be using [pdfplumber](https://https://pypi.org/project/pdfplumber/) to read and process the PDF files.\n",
        "\n",
        "`pdfplumber` allows for better parsing of the PDF file as it can read various elements of the PDF apart from the plain text, such as, tables, images, etc. It also offers wide functionaties and visual debugging features to help with advanced preprocessing as well."
      ],
      "metadata": {
        "id": "l-CoovqcqgkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path of the PDF\n",
        "\n",
        "single_pdf_path = \"/content/drive/My Drive/HelpMate AI Codes/Policy Documents/HDFC-Life-Group-Poorna-Suraksha-101N137V02-Policy-Document.pdf\""
      ],
      "metadata": {
        "id": "D-5PTZeh2l-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color = red>  2.1 Reading a single PDF file and exploring it through pdfplumber"
      ],
      "metadata": {
        "id": "YDMaFpe4p6Dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the PDF file\n",
        "with pdfplumber.open(single_pdf_path) as pdf:\n",
        "\n",
        "    # Get one of the pages from the PDF and examine it\n",
        "    single_page = pdf.pages[6]\n",
        "\n",
        "    # Extract text from the first page\n",
        "    text = single_page.extract_text()\n",
        "\n",
        "    # Extract tables from the first page\n",
        "    tables = single_page.extract_tables()\n",
        "\n",
        "    # Print the extracted text\n",
        "    print(text)"
      ],
      "metadata": {
        "id": "FHFLn9wn2Xea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the table in the page, if any\n",
        "\n",
        "tables[0]"
      ],
      "metadata": {
        "id": "L_1gYHV13vmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color = red> 2.2 Extracting text from multiple PDFs\n",
        "\n",
        "Let's now try and read multiple documents, extract text from them using appropriate preprocessing, and store them in a dataframe\n"
      ],
      "metadata": {
        "id": "BQorWwRMcOhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path where all pdf documents are present\n",
        "\n",
        "pdf_path = \"/content/drive/My Drive/HelpMate AI Codes/Policy Documents\""
      ],
      "metadata": {
        "id": "iw_75A_zQiU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to check whether a word is present in a table or not for segregation of regular text and tables\n",
        "\n",
        "def check_bboxes(word, table_bbox):\n",
        "    # Check whether word is inside a table bbox.\n",
        "    l = word['x0'], word['top'], word['x1'], word['bottom']\n",
        "    r = table_bbox\n",
        "    return l[0] > r[0] and l[1] > r[1] and l[2] < r[2] and l[3] < r[3]"
      ],
      "metadata": {
        "id": "yaRqBDikEi-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract text from a PDF file.\n",
        "# 1. Declare a variable p to store the iteration of the loop that will help us store page numbers alongside the text\n",
        "# 2. Declare an empty list 'full_text' to store all the text files\n",
        "# 3. Use pdfplumber to open the pdf pages one by one\n",
        "# 4. Find the tables and their locations in the page\n",
        "# 5. Extract the text from the tables in the variable 'tables'\n",
        "# 6. Extract the regular words by calling the function check_bboxes() and checking whether words are present in the table or not\n",
        "# 7. Use the cluster_objects utility to cluster non-table and table words together so that they retain the same chronology as in the original PDF\n",
        "# 8. Declare an empty list 'lines' to store the page text\n",
        "# 9. If a text element in present in the cluster, append it to 'lines', else if a table element is present, append the table\n",
        "# 10. Append the page number and all lines to full_text, and increment 'p'\n",
        "# 11. When the function has iterated over all pages, return the 'full_text' list\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    p = 0\n",
        "    full_text = []\n",
        "\n",
        "\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            page_no = f\"Page {p+1}\"\n",
        "            text = page.extract_text()\n",
        "\n",
        "            tables = page.find_tables()\n",
        "            table_bboxes = [i.bbox for i in tables]\n",
        "            tables = [{'table': i.extract(), 'top': i.bbox[1]} for i in tables]\n",
        "            non_table_words = [word for word in page.extract_words() if not any(\n",
        "                [check_bboxes(word, table_bbox) for table_bbox in table_bboxes])]\n",
        "            lines = []\n",
        "\n",
        "            for cluster in pdfplumber.utils.cluster_objects(non_table_words + tables, itemgetter('top'), tolerance=5):\n",
        "\n",
        "                if 'text' in cluster[0]:\n",
        "                    try:\n",
        "                        lines.append(' '.join([i['text'] for i in cluster]))\n",
        "                    except KeyError:\n",
        "                        pass\n",
        "\n",
        "                elif 'table' in cluster[0]:\n",
        "                    lines.append(json.dumps(cluster[0]['table']))\n",
        "\n",
        "\n",
        "            full_text.append([page_no, \" \".join(lines)])\n",
        "            p +=1\n",
        "\n",
        "    return full_text"
      ],
      "metadata": {
        "id": "5vl3fNNvDyBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Now that we have defined the function for extracting the text and tables from a PDF, let's iterate and call this function for all the PDFs in our drive and store them in a list.*"
      ],
      "metadata": {
        "id": "JIBPOBOxefd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory containing the PDF files\n",
        "pdf_directory = Path(pdf_path)\n",
        "\n",
        "# Initialize an empty list to store the extracted texts and document names\n",
        "data = []\n",
        "\n",
        "# Loop through all files in the directory\n",
        "for pdf_path in pdf_directory.glob(\"*.pdf\"):\n",
        "\n",
        "    # Process the PDF file\n",
        "    print(f\"...Processing {pdf_path.name}\")\n",
        "\n",
        "    # Call the function to extract the text from the PDF\n",
        "    extracted_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "    # Convert the extracted list to a PDF, and add a column to store document names\n",
        "    extracted_text_df = pd.DataFrame(extracted_text, columns=['Page No.', 'Page_Text'])\n",
        "    extracted_text_df['Document Name'] = pdf_path.name\n",
        "\n",
        "    # Append the extracted text and document name to the list\n",
        "    data.append(extracted_text_df)\n",
        "\n",
        "    # Print a message to indicate progress\n",
        "    print(f\"Finished processing {pdf_path.name}\")\n",
        "\n",
        "# Print a message to indicate all PDFs have been processed\n",
        "print(\"All PDFs have been processed.\")"
      ],
      "metadata": {
        "id": "gi8dV-BN6U7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate all the DFs in the list 'data' together\n",
        "\n",
        "insurance_pdfs_data = pd.concat(data, ignore_index=True)"
      ],
      "metadata": {
        "id": "xDlL7PADDrrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "insurance_pdfs_data"
      ],
      "metadata": {
        "id": "U9aKtiUhCdjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check one of the extracted page texts to ensure that the text has been correctly read\n",
        "\n",
        "insurance_pdfs_data.Page_Text[2]"
      ],
      "metadata": {
        "id": "QXHBpFzg3s9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's also check the length of all the texts as there might be some empty pages or pages with very few words that we can drop\n",
        "\n",
        "insurance_pdfs_data['Text_Length'] = insurance_pdfs_data['Page_Text'].apply(lambda x: len(x.split(' ')))"
      ],
      "metadata": {
        "id": "a_8T6p99SPdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "insurance_pdfs_data['Text_Length']"
      ],
      "metadata": {
        "id": "uR12GmpRQAKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retain only the rows with a text length of at least 10\n",
        "\n",
        "insurance_pdfs_data = insurance_pdfs_data.loc[insurance_pdfs_data['Text_Length'] >= 10]\n",
        "insurance_pdfs_data"
      ],
      "metadata": {
        "id": "DVRklQV5QC6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the metadata for each page in a separate column\n",
        "\n",
        "insurance_pdfs_data['Metadata'] = insurance_pdfs_data.apply(lambda x: {'Policy_Name': x['Document Name'][:-4], 'Page_No.': x['Page No.']}, axis=1)"
      ],
      "metadata": {
        "id": "9yuq3eOOxfkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "insurance_pdfs_data"
      ],
      "metadata": {
        "id": "2UTsH2QuQmpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This concludes the chunking aspect also, as we can see that mostly the pages contain few hundred words, maximum going upto 1000. So, we don't need to chunk the documents further; we can perform the embeddings on individual pages. This strategy makes sense for 2 reasons:\n",
        "1. The way insurance documents are generally structured, you will not have a lot of extraneous information in a page, and all the text pieces in that page will likely be interrelated.\n",
        "2. We want to have larger chunk sizes to be able to pass appropriate context to the LLM during the generation layer."
      ],
      "metadata": {
        "id": "fBXNi-coqppd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. <font color = red> Generate and Store Embeddings using OpenAI and ChromaDB\n",
        "\n",
        "In this section, we will embed the pages in the dataframe through OpenAI's `text-embedding-ada-002` model, and store them in a ChromaDB collection."
      ],
      "metadata": {
        "id": "oygx9b2VzqIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the API key\n",
        "filepath = \"/content/drive/My Drive/HelpMate AI Codes/\"\n",
        "\n",
        "with open(filepath + \"OpenAI_API_Key.txt\", \"r\") as f:\n",
        "  openai.api_key = ' '.join(f.readlines())"
      ],
      "metadata": {
        "id": "g71qkKV9yUps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the OpenAI Embedding Function into chroma\n",
        "\n",
        "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction"
      ],
      "metadata": {
        "id": "77AYVNHyW1-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path where chroma collections will be stored\n",
        "\n",
        "chroma_data_path = '/content/drive/My Drive/HelpMate AI Codes/ChromaDB_Data'"
      ],
      "metadata": {
        "id": "Pt8q5-CsHEod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call PersistentClient()\n",
        "\n",
        "client = chromadb.PersistentClient(path=chroma_data_path)"
      ],
      "metadata": {
        "id": "Yly1EUXgyiOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the embedding function using the OpenAI embedding model\n",
        "\n",
        "model = \"text-embedding-ada-002\"\n",
        "embedding_function = OpenAIEmbeddingFunction(api_key=openai.api_key, model_name=model)"
      ],
      "metadata": {
        "id": "_1Kyb47vyzzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise a collection in chroma and pass the embedding_function to it so that it used OpenAI embeddings to embed the documents\n",
        "\n",
        "insurance_collection = client.get_or_create_collection(name='RAG_on_Insurance', embedding_function=embedding_function)"
      ],
      "metadata": {
        "id": "MLyU_G-myrPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the page text and metadata from your dataframe to lists to be able to pass it to chroma\n",
        "\n",
        "documents_list = insurance_pdfs_data[\"Page_Text\"].tolist()\n",
        "metadata_list = insurance_pdfs_data['Metadata'].tolist()"
      ],
      "metadata": {
        "id": "_d_jop5hcaQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the documents and metadata to the collection alongwith generic integer IDs. You can also feed the metadata information as IDs by combining the policy name and page no.\n",
        "\n",
        "insurance_collection.add(\n",
        "    documents= documents_list,\n",
        "    ids = [str(i) for i in range(0, len(documents_list))],\n",
        "    metadatas = metadata_list\n",
        ")"
      ],
      "metadata": {
        "id": "QBdLLmyxhFKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's take a look at the first few entries in the collection\n",
        "\n",
        "insurance_collection.get(\n",
        "    ids = ['0','1','2'],\n",
        "    include = ['embeddings', 'documents', 'metadatas']\n",
        ")"
      ],
      "metadata": {
        "id": "92Nr0XTVykX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cache_collection = client.get_or_create_collection(name='Insurance_Cache', embedding_function=embedding_function)"
      ],
      "metadata": {
        "id": "-AzsxvBsdkIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cache_collection.peek()"
      ],
      "metadata": {
        "id": "ayqqoZWlAGXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. <font color = red> Semantic Search with Cache\n",
        "\n",
        "In this section, we will perform a semantic search of a query in the collections embeddings to get several top semantically similar results."
      ],
      "metadata": {
        "id": "VSPM3aJ7lZd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the user query\n",
        "\n",
        "query = input()"
      ],
      "metadata": {
        "id": "7w_JdePjjNoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Searh the Cache collection first\n",
        "# Query the collection against the user query and return the top 20 results\n",
        "\n",
        "cache_results = cache_collection.query(\n",
        "    query_texts=query,\n",
        "    n_results=1\n",
        ")"
      ],
      "metadata": {
        "id": "tPg2D6wXd3Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing Cache in Semantic Search\n",
        "\n",
        "# Set a threshold for cache search\n",
        "threshold = 0.2\n",
        "\n",
        "ids = []\n",
        "documents = []\n",
        "distances = []\n",
        "metadatas = []\n",
        "results_df = pd.DataFrame()\n",
        "\n",
        "\n",
        "# If the distance is greater than the threshold, then return the results from the main collection.\n",
        "\n",
        "if cache_results['distances'][0] == [] or cache_results['distances'][0][0] > threshold:\n",
        "      # Query the collection against the user query and return the top 10 results\n",
        "      results = insurance_collection.query(\n",
        "      query_texts=query,\n",
        "      n_results=10\n",
        "      )\n",
        "\n",
        "      # Store the query in cache_collection as document w.r.t to ChromaDB so that it can be embedded and searched against later\n",
        "      # Store retrieved text, ids, distances and metadatas in cache_collection as metadatas, so that they can be fetched easily if a query indeed matches to a query in cache\n",
        "      Keys = []\n",
        "      Values = []\n",
        "\n",
        "      for key, val in results.items():\n",
        "        if key != 'embeddings':\n",
        "          for i in range(10):\n",
        "            Keys.append(str(key)+str(i))\n",
        "            Values.append(str(val[0][i]))\n",
        "\n",
        "\n",
        "      cache_collection.add(\n",
        "          documents= [query],\n",
        "          ids = [query],  # Or if you want to assign integers as IDs 0,1,2,.., then you can use \"len(cache_results['documents'])\" as will return the no. of queries currently in the cache and assign the next digit to the new query.\"\n",
        "          metadatas = dict(zip(Keys, Values))\n",
        "      )\n",
        "\n",
        "      print(\"Not found in cache. Found in main collection.\")\n",
        "\n",
        "      result_dict = {'Metadatas': results['metadatas'][0], 'Documents': results['documents'][0], 'Distances': results['distances'][0], \"IDs\":results[\"ids\"][0]}\n",
        "      results_df = pd.DataFrame.from_dict(result_dict)\n",
        "      results_df\n",
        "\n",
        "\n",
        "# If the distance is, however, less than the threshold, you can return the results from cache\n",
        "\n",
        "elif cache_results['distances'][0][0] <= threshold:\n",
        "      cache_result_dict = cache_results['metadatas'][0][0]\n",
        "\n",
        "      # Loop through each inner list and then through the dictionary\n",
        "      for key, value in cache_result_dict.items():\n",
        "          if 'ids' in key:\n",
        "              ids.append(value)\n",
        "          elif 'documents' in key:\n",
        "              documents.append(value)\n",
        "          elif 'distances' in key:\n",
        "              distances.append(value)\n",
        "          elif 'metadatas' in key:\n",
        "              metadatas.append(value)\n",
        "\n",
        "      print(\"Found in cache!\")\n",
        "\n",
        "      # Create a DataFrame\n",
        "      results_df = pd.DataFrame({\n",
        "        'IDs': ids,\n",
        "        'Documents': documents,\n",
        "        'Distances': distances,\n",
        "        'Metadatas': metadatas\n",
        "      })\n"
      ],
      "metadata": {
        "id": "fJFO4OYafKCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df"
      ],
      "metadata": {
        "id": "4M2p_b_Mxmmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. <font color = red> Re-Ranking with a Cross Encoder\n",
        "\n",
        "Re-ranking the results obtained from your semantic search can sometime significantly improve the relevance of the retrieved results. This is often done by passing the query paired with each of the retrieved responses into a cross-encoder to score the relevance of the response w.r.t. the query.\n",
        "\n",
        "<br>\n",
        "\n",
        "![Bi_vs_Cross-Encoder.png](data:image/png;base64,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)\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "kHCB3MpXzX_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the CrossEncoder library from sentence_transformers\n",
        "\n",
        "from sentence_transformers import CrossEncoder, util"
      ],
      "metadata": {
        "id": "nLcDXPgIzWNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise the cross encoder model\n",
        "\n",
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
      ],
      "metadata": {
        "id": "FpKFGIm8zWNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the cross encoder model\n",
        "\n",
        "scores = cross_encoder.predict([['Does the insurance cover diabetic patients?', 'The insurance policy covers some pre-existing conditions including diabetes, heart diseases, etc. The policy does not howev'],\n",
        "                                ['Does the insurance cover diabetic patients?', 'The premium rates for various age groups are given as follows. Age group (<18 years): Premium rate']])"
      ],
      "metadata": {
        "id": "t_6t6nAbtA6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "id": "dEzquk9txOKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input (query, response) pairs for each of the top 20 responses received from the semantic search to the cross encoder\n",
        "# Generate the cross_encoder scores for these pairs\n",
        "\n",
        "cross_inputs = [[query, response] for response in results_df['Documents']]\n",
        "cross_rerank_scores = cross_encoder.predict(cross_inputs)"
      ],
      "metadata": {
        "id": "2qjpDrAvzWNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_rerank_scores"
      ],
      "metadata": {
        "id": "J_sNR0wSzWNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the rerank_scores in results_df\n",
        "\n",
        "results_df['Reranked_scores'] = cross_rerank_scores"
      ],
      "metadata": {
        "id": "NJnnPS3FzWNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df"
      ],
      "metadata": {
        "id": "jcp68fNLzWNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Return the top 3 results from semantic search\n",
        "\n",
        "top_3_semantic = results_df.sort_values(by='Distances')\n",
        "top_3_semantic[:3]"
      ],
      "metadata": {
        "id": "1JvPcMRHzWNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Return the top 3 results after reranking\n",
        "\n",
        "top_3_rerank = results_df.sort_values(by='Reranked_scores', ascending=False)\n",
        "top_3_rerank[:3]"
      ],
      "metadata": {
        "id": "vz3Jdm-QzWNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_3_RAG = top_3_rerank[[\"Documents\", \"Metadatas\"]][:3]"
      ],
      "metadata": {
        "id": "mnNXBwnr82OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_3_RAG"
      ],
      "metadata": {
        "id": "6tVPdiYO9JkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Retrieval Augmented Generation\n",
        "\n",
        "Now that we have the final top search results, we can pass it to an GPT 3.5 along with the user query and a well-engineered prompt, to generate a direct answer to the query along with citations, rather than returning whole pages/chunks."
      ],
      "metadata": {
        "id": "si6lniu8rfDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function to generate the response. Provide a comprehensive prompt that passes the user query and the top 3 results to the model\n",
        "\n",
        "def generate_response(query, results_df):\n",
        "    \"\"\"\n",
        "    Generate a response using GPT-3.5's ChatCompletion based on the user query and retrieved information.\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "                {\"role\": \"system\", \"content\":  \"You are a helpful assistant in the insurance domain who can effectively answer user queries about insurance policies and documents.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"\"\"You are a helpful assistant in the insurance domain who can effectively answer user queries about insurance policies and documents.\n",
        "                                                You have a question asked by the user in '{query}' and you have some search results from a corpus of insurance documents in the dataframe '{top_3_RAG}'. These search results are essentially one page of an insurance document that may be relevant to the user query.\n",
        "\n",
        "                                                The column 'documents' inside this dataframe contains the actual text from the policy document and the column 'metadata' contains the policy name and source page. The text inside the document may also contain tables in the format of a list of lists where each of the nested lists indicates a row.\n",
        "\n",
        "                                                Use the documents in '{top_3_RAG}' to answer the query '{query}'. Frame an informative answer and also, use the dataframe to return the relevant policy names and page numbers as citations.\n",
        "\n",
        "                                                Follow the guidelines below when performing the task.\n",
        "                                                1. Try to provide relevant/accurate numbers if available.\n",
        "                                                2. You donâ€™t have to necessarily use all the information in the dataframe. Only choose information that is relevant.\n",
        "                                                3. If the document text has tables with relevant information, please reformat the table and return the final information in a tabular in format.\n",
        "                                                3. Use the Metadatas columns in the dataframe to retrieve and cite the policy name(s) and page numbers(s) as citation.\n",
        "                                                4. If you can't provide the complete answer, please also provide any information that will help the user to search specific sections in the relevant cited documents.\n",
        "                                                5. You are a customer facing assistant, so do not provide any information on internal workings, just answer the query directly.\n",
        "\n",
        "                                                The generated response should answer the query directly addressing the user and avoiding additional information. If you think that the query is not relevant to the document, reply that the query is irrelevant. Provide the final response as a well-formatted and easily readable text along with the citation. Provide your complete response first with all information, and then provide the citations.\n",
        "\n",
        "                                                \"\"\"},\n",
        "              ]\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    return response['choices'][0]['message']['content'].split('\\n')"
      ],
      "metadata": {
        "id": "kE9G23UnkL8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the response\n",
        "\n",
        "response = generate_response(query, top_3_RAG)"
      ],
      "metadata": {
        "id": "wnRLO3ONmjFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the response\n",
        "\n",
        "print(\"\\n\".join(response))"
      ],
      "metadata": {
        "id": "uN9hMmLymlY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bLc70M407zJx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}